{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datatable as dt\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "data = dt.fread('~/jane-street-market-prediction/train.csv').to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499]\n",
      "[403 211 149 247 183   0  85 470 338 435 495 122 301 490 462 370  30 156\n",
      " 254 483 332  54 238 382 145 333 384 409 215 427  77 128 235 308  68 296\n",
      " 450 440 328  56 327 157 454 318 400 141 335  32  12 105 281 322 398 117\n",
      "  40   5 331 280  70 476  62 443 173   9 253 311 121 268 176  69 437 449\n",
      " 496 394 343  76 269 277 234 205 220  18 134 305 359 185 265 498 161 290\n",
      " 416  83 412 337 430 133 103 226  66 371 150 177 355  53 136 406 429 303\n",
      " 252 246 341 195  98 390 321 159 418 230 158 362  47 111 446 106  90  89\n",
      "  39 388 451 438 465 110 223 283 104 319 419 325 347 468 227 407   8 131\n",
      " 114 213  99  84  94 262  97  74 392 494 255 488 324 266 152   2 368  21\n",
      " 426 174 404 144 415 237 116  65 251 260 218 292 361 487 467 286 291 249\n",
      " 132 374 182  50 436  20 236 190 317 169 334  58 354 363 164 448 309 391\n",
      " 295 493 491 474 297  35 273 480 100 380 372  52 289 477 264   4 302 165\n",
      "  14 233 214 373 274  29 344   3 201 139 272 460 379 256 243 492  17 473\n",
      " 279 198 193   7 123 151 263 478  93 376 410 481  55 402  11 348 306 275\n",
      "  57  15  46 330 340 244  78  60 444 441 366 469 162 270 349 124 423 232\n",
      "  48 222 345 166 342  10  34 206 170  91  64 178 112  88 369 225  13 285\n",
      " 120  33 171 101 396  26 137 204 299  42 307 181 207 466 192  61 439 199\n",
      " 479 386  37  16 188 358 130 242 271  44 278  31 399  79 471 413 360 367\n",
      " 298  24  81 191 118 422 432 329 288 119 126 200 245 209 395 408 433 378\n",
      " 387  80 313 357 339 216  63 107 138 336 452 160  38 282 356 287 248 228\n",
      " 463 312 475 109 224 486 197 208 365 389 221  25 351 239 397 499 304 102\n",
      "  71 142 482  73  43 194 175  96 447 320 276 350 453 115   6 323 458 381\n",
      " 261  19 146 485  22  67 186  87 424  27 421 472 257 212 417 428 315 217\n",
      " 401 497 129 143  36 202 375 420 147 411 155 352 442  23 489 241 167 108\n",
      " 459  92 364 284 179  28 300 180 267 461 326  72  86 140 377 163 405 240\n",
      " 385 127 219 425 457 346 154  59  51 316 464 456 203  95 259 393 293  82\n",
      "   1  75 414 250 231 455 294 148 168 434  45 431 445 353 314 153  41 187\n",
      " 196 135 210 172 484 189 229  49 310 125 184 113 383 258]\n"
     ]
    }
   ],
   "source": [
    "unique_dates = np.unique(data['date'] )\n",
    "print(unique_dates)\n",
    "np.random.shuffle(unique_dates)\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "idx = np.linspace(start = 0, stop = len(unique_dates)-1, num = folds + 1, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['date'].isin(unique_dates[idx[0]:idx[0+1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_mlp2(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x) #(x)\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "        #x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, inp])\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "idx = np.linspace(start = 0, stop = len(unique_dates)-1, num = folds + 1, dtype = int)\n",
    "for f in range(folds):\n",
    "    mask = data['date'].isin(unique_dates[idx[f]:idx[f+1]] )\n",
    "    train = data[~mask]\n",
    "    val = data[mask]\n",
    "    \n",
    "    train.fillna(train.mean(),inplace=True)\n",
    "\n",
    "    features = [c for c in train.columns if \"feature\" in c]\n",
    "\n",
    "    f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "    X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "    y_train = (train.loc[:, 'action'])\n",
    "    \n",
    "\n",
    "    batch_size = 5000\n",
    "    hidden_units = [260, 260, 130]\n",
    "    dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "    label_smoothing = 1e-2\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    clf = create_mlp2(\n",
    "        len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "        )\n",
    "\n",
    "    clf.fit(X_train, y_train, epochs=200, batch_size=20000)\n",
    "\n",
    "    opt_th = 0.5000\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = train[['date', 'resp','weight']]\n",
    "pred_df['actual'] = ((train['resp'].values) > 0).astype(int)\n",
    "preds = clf(X_train.values, training=False)\n",
    "pred_df['preds'] = preds.numpy()\n",
    "pred_df['action'] = (pred_df['preds'] >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def utility_score(df,action_vec):\n",
    "    \"\"\"Calculate utility score of a dataframe according to formulas defined at\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    p = df['weight']  * df['resp'] * action_vec\n",
    "    df['p'] = p\n",
    "    p_i = df.set_index('date')['p'].groupby('date').sum()\n",
    "    t = (p_i.sum() / sqrt((p_i**2).sum())) * (sqrt(250 / p_i.index.size))\n",
    "    return min(max(t, 0), 6) * p_i.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['preds'] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['action'] = (pred_df['preds'] >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_score(pred_df, pred_df['action']) / utility_score(pred_df, pred_df['actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_tf] *",
   "language": "python",
   "name": "conda-env-kaggle_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
