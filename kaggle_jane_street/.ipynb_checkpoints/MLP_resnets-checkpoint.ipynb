{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datatable as dt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train = dt.fread('~/jane-street-market-prediction/train.csv').to_pandas()\n",
    "\n",
    "\n",
    "#train = pd.read_csv('~/jane-street-market-prediction/train.csv')\n",
    "train = train.query('date > 85').reset_index(drop = True) \n",
    "#train = train[train['weight'] != 0]\n",
    "\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "\n",
    "train['action'] = ((train['resp'].values) < 0).astype(int)\n",
    "\n",
    "\n",
    "features = [c for c in train.columns if \"feature\" in c]\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "y_train = (train.loc[:, 'action'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 5.54208343e-01, 5.56405846e-01,\n",
       "       5.47827908e-01, 5.22204943e-01, 5.25096056e-01, 1.00000000e+00,\n",
       "       7.15267095e-02, 3.77826448e-02, 4.89709567e-01, 4.88882881e-01,\n",
       "       4.97764769e-01, 4.70222864e-01, 4.35471458e-01, 4.96130090e-01,\n",
       "       7.30574038e-01, 6.11491011e-01, 5.22416043e-01, 4.87423836e-01,\n",
       "       6.15330084e-01, 5.73971185e-01, 7.01602812e-01, 5.58587265e-01,\n",
       "       4.05330093e-01, 4.96360563e-01, 4.85889008e-01, 5.56207786e-01,\n",
       "       4.86971327e-01, 4.85884901e-01, 5.49391020e-01, 5.49767867e-01,\n",
       "       5.41514572e-01, 5.58987648e-01, 5.41534387e-01, 4.96049019e-01,\n",
       "       7.61015453e-01, 6.07758556e-01, 5.79966065e-01, 4.82910562e-01,\n",
       "       5.97398087e-01, 5.46631846e-01, 7.07886152e-01, 5.35625271e-01,\n",
       "       5.02972379e-01, 5.06457967e-01, 4.90760593e-01, 4.90314161e-01,\n",
       "       1.28496843e-01, 3.55727676e-01, 4.21165036e-01, 6.56619621e-02,\n",
       "       3.31082988e-02, 8.83722988e-03, 1.10542067e-01, 1.35798098e-02,\n",
       "       5.21843298e-03, 8.79815255e-03, 1.46910081e-02, 3.06764295e-01,\n",
       "       1.64908874e-01, 2.32240624e-02, 1.12217612e-02, 8.76049914e-04,\n",
       "       6.29855039e-03, 8.63128556e-03, 2.85113575e-03, 2.95382990e-01,\n",
       "       2.77020603e-01, 2.18797459e-01, 2.47492010e-01, 1.18687161e-01,\n",
       "       2.38022066e-01, 1.84915305e-01, 2.96467339e-01, 2.93885300e-01,\n",
       "       1.26268277e-01, 3.39981558e-02, 6.59486342e-02, 5.86381541e-01,\n",
       "       4.81775441e-01, 5.86025584e-01, 6.20098913e-01, 5.19544608e-01,\n",
       "       6.19172213e-01, 6.15639821e-01, 6.22921168e-01, 6.05817059e-01,\n",
       "       6.44869436e-01, 6.64577276e-01, 6.66012747e-01, 2.40748490e-02,\n",
       "       0.00000000e+00, 2.00496072e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.06967180e-02, 6.09716615e-02, 0.00000000e+00, 3.20674632e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.97692363e-02, 3.02746002e-02,\n",
       "       2.71201788e-02, 1.87333175e-02, 1.12983694e-02, 2.05146310e-02,\n",
       "       1.05633419e-02, 6.13610741e-02, 2.82554352e-03, 2.36649603e-02,\n",
       "       4.06655254e-03, 4.47265064e-03, 2.33595865e-02, 5.36773165e-02,\n",
       "       4.55397172e-02, 2.20511511e-02, 1.64986344e-02, 3.84732041e-02,\n",
       "       2.09223030e-02, 7.35616865e-02, 4.94558973e-03, 6.06127154e-02,\n",
       "       8.72955041e-03, 5.17888162e-03, 2.70145894e-02, 7.25664958e-02,\n",
       "       6.53447790e-02, 1.71956321e-01, 3.89262545e-02, 8.97802221e-02,\n",
       "       8.96756166e-02, 1.58981070e-01, 6.67197718e-02, 1.62977466e-01,\n",
       "       3.81398558e-02, 5.36885079e-07, 0.00000000e+00])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               86.000000\n",
       "weight              0.000000\n",
       "resp_1             -0.009107\n",
       "resp_2             -0.013542\n",
       "resp_3             -0.022222\n",
       "                   ...      \n",
       "feature_127        -0.756115\n",
       "feature_128         2.210572\n",
       "feature_129        -0.639075\n",
       "ts_id          527895.000000\n",
       "action              1.000000\n",
       "Name: 1, Length: 139, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x) #(x)\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "        #x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, inp])\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4cffe4b768f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mopt_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    620\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 5000\n",
    "hidden_units = [130, 130, 130]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "clf = create_mlp(\n",
    "    len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train, epochs=200, batch_size=20000)\n",
    "\n",
    "opt_th = 0.5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def utility_score(df,action_vec):\n",
    "    \"\"\"Calculate utility score of a dataframe according to formulas defined at\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    p = df['weight']  * df['resp'] * action_vec\n",
    "    df['p'] = p\n",
    "    p_i = df.set_index('date')['p'].groupby('date').sum()\n",
    "    t = (p_i.sum() / sqrt((p_i**2).sum())) * (sqrt(250 / p_i.index.size))\n",
    "    return min(max(t, 0), 6) * p_i.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1862597, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf(X_train.values, training=False)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.461457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862592</th>\n",
       "      <td>0.516960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862593</th>\n",
       "      <td>0.558398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862594</th>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862595</th>\n",
       "      <td>0.378754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862596</th>\n",
       "      <td>0.442022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1862597 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0        0.565858\n",
       "1        0.563406\n",
       "2        0.461457\n",
       "3        0.509057\n",
       "4        0.512825\n",
       "...           ...\n",
       "1862592  0.516960\n",
       "1862593  0.558398\n",
       "1862594  0.515000\n",
       "1862595  0.378754\n",
       "1862596  0.442022\n",
       "\n",
       "[1862597 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-94a18930434c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['actual'] = ((train['resp'].values) > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "pred_df = train[['date', 'resp','weight']]\n",
    "pred_df['actual'] = ((train['resp'].values) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-910f3630f103>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['preds'] = preds.numpy()\n"
     ]
    }
   ],
   "source": [
    "pred_df['preds'] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>resp</th>\n",
       "      <th>weight</th>\n",
       "      <th>actual</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.021435</td>\n",
       "      <td>0.859516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.026394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.590949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date      resp    weight  actual     preds\n",
       "0    86 -0.021435  0.859516       0  0.565858\n",
       "1    86 -0.026394  0.000000       0  0.563406\n",
       "2    86 -0.004743  0.590949       0  0.461457\n",
       "3    86  0.001527  0.172997       1  0.509057\n",
       "4    86 -0.000139  0.000000       0  0.512825"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-c89a10eba162>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] = (pred_df['preds'] >= 0.5) * 1\n"
     ]
    }
   ],
   "source": [
    "pred_df['action'] = (pred_df['preds'] >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9f86764eae83>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21829881020692002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_score(pred_df, pred_df['action']) / utility_score(pred_df, pred_df['actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_mlp2(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x) #(x)\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "        #x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, inp])\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "94/94 [==============================] - 4s 24ms/step - loss: 0.7771 - AUC: 0.5035\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.7064 - AUC: 0.5079\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6998 - AUC: 0.5128\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6964 - AUC: 0.5163\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6946 - AUC: 0.5189\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6934 - AUC: 0.5229\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6926 - AUC: 0.5254\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6921 - AUC: 0.5277\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6918 - AUC: 0.5301\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6915 - AUC: 0.5320\n",
      "Epoch 11/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6913 - AUC: 0.5328\n",
      "Epoch 12/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6911 - AUC: 0.5341\n",
      "Epoch 13/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6910 - AUC: 0.5337\n",
      "Epoch 14/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6908 - AUC: 0.5355\n",
      "Epoch 15/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6905 - AUC: 0.5374\n",
      "Epoch 16/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6904 - AUC: 0.5377\n",
      "Epoch 17/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6902 - AUC: 0.5387\n",
      "Epoch 18/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6901 - AUC: 0.5395\n",
      "Epoch 19/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6898 - AUC: 0.5409\n",
      "Epoch 20/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6896 - AUC: 0.5414\n",
      "Epoch 21/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6894 - AUC: 0.5419\n",
      "Epoch 22/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6891 - AUC: 0.5435\n",
      "Epoch 23/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6887 - AUC: 0.5449\n",
      "Epoch 24/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6885 - AUC: 0.5462\n",
      "Epoch 25/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6882 - AUC: 0.5468\n",
      "Epoch 26/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6878 - AUC: 0.5479\n",
      "Epoch 27/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6875 - AUC: 0.5493\n",
      "Epoch 28/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6869 - AUC: 0.5512\n",
      "Epoch 29/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6867 - AUC: 0.5519\n",
      "Epoch 30/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6863 - AUC: 0.5526\n",
      "Epoch 31/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6860 - AUC: 0.5534\n",
      "Epoch 32/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6853 - AUC: 0.5564\n",
      "Epoch 33/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6851 - AUC: 0.5559\n",
      "Epoch 34/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6847 - AUC: 0.5577\n",
      "Epoch 35/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6843 - AUC: 0.5578\n",
      "Epoch 36/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6841 - AUC: 0.5584\n",
      "Epoch 37/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6834 - AUC: 0.5610\n",
      "Epoch 38/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6832 - AUC: 0.5612\n",
      "Epoch 39/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6827 - AUC: 0.5628\n",
      "Epoch 40/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6826 - AUC: 0.5624\n",
      "Epoch 41/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6820 - AUC: 0.5641\n",
      "Epoch 42/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6815 - AUC: 0.5652\n",
      "Epoch 43/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6811 - AUC: 0.5667\n",
      "Epoch 44/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6809 - AUC: 0.5669\n",
      "Epoch 45/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6805 - AUC: 0.5678\n",
      "Epoch 46/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6801 - AUC: 0.5691\n",
      "Epoch 47/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6797 - AUC: 0.5698\n",
      "Epoch 48/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6795 - AUC: 0.5698\n",
      "Epoch 49/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6791 - AUC: 0.5712\n",
      "Epoch 50/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6791 - AUC: 0.5710\n",
      "Epoch 51/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6786 - AUC: 0.5726\n",
      "Epoch 52/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6782 - AUC: 0.5736\n",
      "Epoch 53/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6778 - AUC: 0.5743\n",
      "Epoch 54/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6778 - AUC: 0.5747\n",
      "Epoch 55/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6771 - AUC: 0.5762\n",
      "Epoch 56/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6770 - AUC: 0.5761\n",
      "Epoch 57/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6771 - AUC: 0.5766\n",
      "Epoch 58/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6766 - AUC: 0.5776\n",
      "Epoch 59/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6761 - AUC: 0.5785\n",
      "Epoch 60/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6760 - AUC: 0.5788\n",
      "Epoch 61/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6756 - AUC: 0.5790\n",
      "Epoch 62/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6753 - AUC: 0.5801\n",
      "Epoch 63/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6754 - AUC: 0.5803\n",
      "Epoch 64/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6750 - AUC: 0.5809\n",
      "Epoch 65/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6749 - AUC: 0.5812\n",
      "Epoch 66/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6745 - AUC: 0.5820\n",
      "Epoch 67/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6744 - AUC: 0.5831\n",
      "Epoch 68/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6739 - AUC: 0.5840\n",
      "Epoch 69/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6738 - AUC: 0.5837\n",
      "Epoch 70/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6737 - AUC: 0.5841\n",
      "Epoch 71/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6736 - AUC: 0.5848\n",
      "Epoch 72/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6734 - AUC: 0.5844\n",
      "Epoch 73/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6731 - AUC: 0.5860\n",
      "Epoch 74/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6727 - AUC: 0.5866\n",
      "Epoch 75/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6726 - AUC: 0.5868\n",
      "Epoch 76/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6723 - AUC: 0.5874\n",
      "Epoch 77/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6725 - AUC: 0.5866\n",
      "Epoch 78/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6726 - AUC: 0.5865\n",
      "Epoch 79/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6718 - AUC: 0.5888\n",
      "Epoch 80/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6720 - AUC: 0.5880\n",
      "Epoch 81/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6719 - AUC: 0.5878\n",
      "Epoch 82/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6716 - AUC: 0.5897\n",
      "Epoch 83/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6716 - AUC: 0.5888\n",
      "Epoch 84/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6714 - AUC: 0.5891\n",
      "Epoch 85/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6710 - AUC: 0.5899\n",
      "Epoch 86/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6707 - AUC: 0.5902\n",
      "Epoch 87/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6708 - AUC: 0.5902\n",
      "Epoch 88/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6709 - AUC: 0.5901\n",
      "Epoch 89/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6706 - AUC: 0.5914\n",
      "Epoch 90/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6702 - AUC: 0.5921\n",
      "Epoch 91/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6699 - AUC: 0.5925\n",
      "Epoch 92/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6703 - AUC: 0.5919\n",
      "Epoch 93/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6698 - AUC: 0.5929\n",
      "Epoch 94/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6698 - AUC: 0.5927\n",
      "Epoch 95/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6698 - AUC: 0.5928\n",
      "Epoch 96/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6694 - AUC: 0.5944\n",
      "Epoch 97/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6691 - AUC: 0.5948\n",
      "Epoch 98/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6694 - AUC: 0.5942\n",
      "Epoch 99/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6690 - AUC: 0.5941\n",
      "Epoch 100/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6690 - AUC: 0.5945\n",
      "Epoch 101/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6690 - AUC: 0.5949\n",
      "Epoch 102/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6688 - AUC: 0.5955\n",
      "Epoch 103/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6685 - AUC: 0.5963\n",
      "Epoch 104/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6685 - AUC: 0.5957\n",
      "Epoch 105/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6685 - AUC: 0.5955\n",
      "Epoch 106/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6685 - AUC: 0.5957\n",
      "Epoch 107/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6681 - AUC: 0.5967\n",
      "Epoch 108/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6680 - AUC: 0.5969\n",
      "Epoch 109/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6680 - AUC: 0.5975\n",
      "Epoch 110/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6677 - AUC: 0.5968\n",
      "Epoch 111/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6680 - AUC: 0.5975\n",
      "Epoch 112/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6680 - AUC: 0.5970\n",
      "Epoch 113/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6677 - AUC: 0.5973\n",
      "Epoch 114/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6676 - AUC: 0.5972\n",
      "Epoch 115/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6673 - AUC: 0.5984\n",
      "Epoch 116/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6672 - AUC: 0.5980\n",
      "Epoch 117/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6672 - AUC: 0.5992\n",
      "Epoch 118/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6670 - AUC: 0.5984\n",
      "Epoch 119/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6669 - AUC: 0.5992\n",
      "Epoch 120/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6669 - AUC: 0.5989\n",
      "Epoch 121/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6668 - AUC: 0.5989\n",
      "Epoch 122/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6665 - AUC: 0.5996\n",
      "Epoch 123/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6666 - AUC: 0.6000\n",
      "Epoch 124/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6668 - AUC: 0.6000\n",
      "Epoch 125/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6666 - AUC: 0.6001\n",
      "Epoch 126/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6666 - AUC: 0.6003\n",
      "Epoch 127/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6664 - AUC: 0.6006\n",
      "Epoch 128/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6663 - AUC: 0.6003\n",
      "Epoch 129/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6660 - AUC: 0.6013\n",
      "Epoch 130/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6662 - AUC: 0.6008\n",
      "Epoch 131/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6661 - AUC: 0.6010\n",
      "Epoch 132/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6659 - AUC: 0.6014\n",
      "Epoch 133/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6661 - AUC: 0.6006\n",
      "Epoch 134/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6657 - AUC: 0.6015\n",
      "Epoch 135/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6657 - AUC: 0.6020\n",
      "Epoch 136/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6658 - AUC: 0.6020\n",
      "Epoch 137/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6654 - AUC: 0.6029\n",
      "Epoch 138/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6658 - AUC: 0.6020\n",
      "Epoch 139/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6655 - AUC: 0.6025\n",
      "Epoch 140/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6652 - AUC: 0.6030\n",
      "Epoch 141/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6658 - AUC: 0.6024\n",
      "Epoch 142/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6654 - AUC: 0.6024\n",
      "Epoch 143/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6652 - AUC: 0.6032\n",
      "Epoch 144/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6652 - AUC: 0.6027\n",
      "Epoch 145/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6652 - AUC: 0.6030\n",
      "Epoch 146/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6653 - AUC: 0.6029\n",
      "Epoch 147/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6652 - AUC: 0.6030\n",
      "Epoch 148/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6648 - AUC: 0.6034\n",
      "Epoch 149/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6648 - AUC: 0.6043\n",
      "Epoch 150/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6647 - AUC: 0.6038\n",
      "Epoch 151/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6645 - AUC: 0.6048\n",
      "Epoch 152/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6644 - AUC: 0.6047\n",
      "Epoch 153/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6648 - AUC: 0.6037\n",
      "Epoch 154/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6644 - AUC: 0.6044\n",
      "Epoch 155/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6642 - AUC: 0.6049\n",
      "Epoch 156/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6643 - AUC: 0.6047\n",
      "Epoch 157/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6642 - AUC: 0.6048\n",
      "Epoch 158/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6644 - AUC: 0.6044\n",
      "Epoch 159/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6643 - AUC: 0.6052\n",
      "Epoch 160/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6641 - AUC: 0.6053\n",
      "Epoch 161/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6640 - AUC: 0.6057\n",
      "Epoch 162/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6639 - AUC: 0.6061\n",
      "Epoch 163/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6637 - AUC: 0.6064\n",
      "Epoch 164/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6640 - AUC: 0.6060\n",
      "Epoch 165/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6642 - AUC: 0.6056\n",
      "Epoch 166/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6640 - AUC: 0.6055\n",
      "Epoch 167/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6637 - AUC: 0.6058\n",
      "Epoch 168/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6639 - AUC: 0.6060\n",
      "Epoch 169/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6636 - AUC: 0.6063\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6633 - AUC: 0.6065\n",
      "Epoch 171/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6637 - AUC: 0.6066\n",
      "Epoch 172/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6637 - AUC: 0.6062\n",
      "Epoch 173/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6631 - AUC: 0.6073\n",
      "Epoch 174/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6634 - AUC: 0.6069\n",
      "Epoch 175/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6634 - AUC: 0.6072\n",
      "Epoch 176/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6633 - AUC: 0.6065\n",
      "Epoch 177/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6635 - AUC: 0.6067\n",
      "Epoch 178/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6632 - AUC: 0.6073\n",
      "Epoch 179/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6631 - AUC: 0.6075\n",
      "Epoch 180/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6628 - AUC: 0.6082\n",
      "Epoch 181/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6631 - AUC: 0.6072\n",
      "Epoch 182/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6628 - AUC: 0.6078\n",
      "Epoch 183/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6633 - AUC: 0.6071\n",
      "Epoch 184/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6627 - AUC: 0.6083\n",
      "Epoch 185/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6629 - AUC: 0.6080\n",
      "Epoch 186/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6629 - AUC: 0.6079\n",
      "Epoch 187/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6628 - AUC: 0.6079\n",
      "Epoch 188/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6630 - AUC: 0.6077\n",
      "Epoch 189/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6625 - AUC: 0.6086\n",
      "Epoch 190/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6628 - AUC: 0.6085\n",
      "Epoch 191/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6631 - AUC: 0.6067\n",
      "Epoch 192/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6625 - AUC: 0.6083\n",
      "Epoch 193/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6626 - AUC: 0.6084\n",
      "Epoch 194/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6624 - AUC: 0.6088\n",
      "Epoch 195/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6624 - AUC: 0.6085\n",
      "Epoch 196/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6629 - AUC: 0.6085\n",
      "Epoch 197/200\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 0.6623 - AUC: 0.6093\n",
      "Epoch 198/200\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 0.6621 - AUC: 0.6096\n",
      "Epoch 199/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6624 - AUC: 0.6092\n",
      "Epoch 200/200\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.6621 - AUC: 0.6090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 5000\n",
    "hidden_units = [260, 260, 130]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "clf2 = create_mlp2(\n",
    "    len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf2.fit(X_train, y_train, epochs=200, batch_size=20000)\n",
    "\n",
    "opt_th = 0.5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-62e771475bf9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['actual'] = ((train['resp'].values) > 0).astype(int)\n",
      "<ipython-input-26-62e771475bf9>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['preds'] = preds.numpy()\n",
      "<ipython-input-26-62e771475bf9>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] = (pred_df['preds'] >= 0.5) * 1\n"
     ]
    }
   ],
   "source": [
    "preds = clf2(X_train.values, training=False)\n",
    "preds.shape\n",
    "pred_df = train[['date', 'resp','weight']]\n",
    "pred_df['actual'] = ((train['resp'].values) > 0).astype(int)\n",
    "pred_df['preds'] = preds.numpy()\n",
    "pred_df['action'] = (pred_df['preds'] >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9f86764eae83>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28698028692794086"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_score(pred_df, pred_df['action']) / utility_score(pred_df, pred_df['actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9f86764eae83>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49876.53116843481"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_score(pred_df, pred_df['action']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_tf] *",
   "language": "python",
   "name": "conda-env-kaggle_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
