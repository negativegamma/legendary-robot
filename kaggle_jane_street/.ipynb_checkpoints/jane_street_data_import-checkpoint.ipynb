{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datatable as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = '~/jane-street-market-prediction/train.csv'\n",
    "\n",
    "data = dt.fread(filepath).to_pandas()\n",
    "\n",
    "\n",
    "#data = pd.read_csv(filepath)\n",
    "data=data[data.weight!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '~/jane-street-market-prediction/train.csv'\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3         -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.320637e+06</td>\n",
       "      <td>2.390268e+06</td>\n",
       "      <td>2.390268e+06</td>\n",
       "      <td>2.374408e+06</td>\n",
       "      <td>2.374408e+06</td>\n",
       "      <td>2.381638e+06</td>\n",
       "      <td>2.381638e+06</td>\n",
       "      <td>2.388570e+06</td>\n",
       "      <td>2.388570e+06</td>\n",
       "      <td>2.390491e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.478668e+02</td>\n",
       "      <td>3.031535e+00</td>\n",
       "      <td>1.434969e-04</td>\n",
       "      <td>1.980749e-04</td>\n",
       "      <td>2.824183e-04</td>\n",
       "      <td>4.350201e-04</td>\n",
       "      <td>4.083113e-04</td>\n",
       "      <td>9.838565e-03</td>\n",
       "      <td>3.855776e-01</td>\n",
       "      <td>3.576875e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.687757e-01</td>\n",
       "      <td>3.435523e-01</td>\n",
       "      <td>2.799973e-01</td>\n",
       "      <td>3.351537e-01</td>\n",
       "      <td>2.448752e-01</td>\n",
       "      <td>3.391778e-01</td>\n",
       "      <td>2.323809e-01</td>\n",
       "      <td>3.425608e-01</td>\n",
       "      <td>2.456182e-01</td>\n",
       "      <td>1.195245e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.522746e+02</td>\n",
       "      <td>7.672794e+00</td>\n",
       "      <td>8.930163e-03</td>\n",
       "      <td>1.230236e-02</td>\n",
       "      <td>1.906882e-02</td>\n",
       "      <td>3.291224e-02</td>\n",
       "      <td>2.693609e-02</td>\n",
       "      <td>9.999518e-01</td>\n",
       "      <td>2.559373e+00</td>\n",
       "      <td>2.477335e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.174238e+00</td>\n",
       "      <td>2.087842e+00</td>\n",
       "      <td>1.977643e+00</td>\n",
       "      <td>1.742587e+00</td>\n",
       "      <td>2.242853e+00</td>\n",
       "      <td>2.534498e+00</td>\n",
       "      <td>1.795854e+00</td>\n",
       "      <td>2.307130e+00</td>\n",
       "      <td>1.765419e+00</td>\n",
       "      <td>6.900755e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.675043e-01</td>\n",
       "      <td>-5.328334e-01</td>\n",
       "      <td>-5.681196e-01</td>\n",
       "      <td>-5.987447e-01</td>\n",
       "      <td>-5.493845e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-3.172026e+00</td>\n",
       "      <td>-3.093182e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.471971e+00</td>\n",
       "      <td>-5.862979e+00</td>\n",
       "      <td>-6.029281e+00</td>\n",
       "      <td>-4.080720e+00</td>\n",
       "      <td>-8.136407e+00</td>\n",
       "      <td>-8.215050e+00</td>\n",
       "      <td>-5.765982e+00</td>\n",
       "      <td>-7.024909e+00</td>\n",
       "      <td>-5.282181e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.040000e+02</td>\n",
       "      <td>1.617400e-01</td>\n",
       "      <td>-1.859162e-03</td>\n",
       "      <td>-2.655044e-03</td>\n",
       "      <td>-5.030704e-03</td>\n",
       "      <td>-9.310415e-03</td>\n",
       "      <td>-7.157903e-03</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.299334e+00</td>\n",
       "      <td>-1.263628e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123252e+00</td>\n",
       "      <td>-1.114326e+00</td>\n",
       "      <td>-9.512009e-01</td>\n",
       "      <td>-9.133750e-01</td>\n",
       "      <td>-1.212124e+00</td>\n",
       "      <td>-1.452912e+00</td>\n",
       "      <td>-8.993050e-01</td>\n",
       "      <td>-1.278341e+00</td>\n",
       "      <td>-8.544535e-01</td>\n",
       "      <td>5.976225e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.540000e+02</td>\n",
       "      <td>7.086770e-01</td>\n",
       "      <td>4.552665e-05</td>\n",
       "      <td>6.928179e-05</td>\n",
       "      <td>1.164734e-04</td>\n",
       "      <td>1.222579e-04</td>\n",
       "      <td>8.634997e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.870182e-05</td>\n",
       "      <td>-7.200577e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.006233e-17</td>\n",
       "      <td>6.054629e-17</td>\n",
       "      <td>4.870826e-17</td>\n",
       "      <td>-2.558675e-16</td>\n",
       "      <td>1.015055e-16</td>\n",
       "      <td>5.419920e-17</td>\n",
       "      <td>8.563069e-17</td>\n",
       "      <td>4.869529e-17</td>\n",
       "      <td>1.195245e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.820000e+02</td>\n",
       "      <td>2.471791e+00</td>\n",
       "      <td>2.097469e-03</td>\n",
       "      <td>2.939111e-03</td>\n",
       "      <td>5.466336e-03</td>\n",
       "      <td>9.804649e-03</td>\n",
       "      <td>7.544347e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.578417e+00</td>\n",
       "      <td>1.526399e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342829e+00</td>\n",
       "      <td>1.405926e+00</td>\n",
       "      <td>1.308625e+00</td>\n",
       "      <td>1.228277e+00</td>\n",
       "      <td>1.409687e+00</td>\n",
       "      <td>1.767275e+00</td>\n",
       "      <td>1.111491e+00</td>\n",
       "      <td>1.582633e+00</td>\n",
       "      <td>1.125321e+00</td>\n",
       "      <td>1.792868e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.990000e+02</td>\n",
       "      <td>1.672937e+02</td>\n",
       "      <td>2.453477e-01</td>\n",
       "      <td>2.949339e-01</td>\n",
       "      <td>3.265597e-01</td>\n",
       "      <td>5.113795e-01</td>\n",
       "      <td>4.484616e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.442989e+01</td>\n",
       "      <td>1.480763e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107771e+02</td>\n",
       "      <td>4.812516e+01</td>\n",
       "      <td>1.276908e+02</td>\n",
       "      <td>6.514517e+01</td>\n",
       "      <td>7.052807e+01</td>\n",
       "      <td>5.872849e+01</td>\n",
       "      <td>6.932221e+01</td>\n",
       "      <td>5.119038e+01</td>\n",
       "      <td>1.164568e+02</td>\n",
       "      <td>2.390490e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date        weight        resp_1        resp_2        resp_3  \\\n",
       "count  2.390491e+06  2.390491e+06  2.390491e+06  2.390491e+06  2.390491e+06   \n",
       "mean   2.478668e+02  3.031535e+00  1.434969e-04  1.980749e-04  2.824183e-04   \n",
       "std    1.522746e+02  7.672794e+00  8.930163e-03  1.230236e-02  1.906882e-02   \n",
       "min    0.000000e+00  0.000000e+00 -3.675043e-01 -5.328334e-01 -5.681196e-01   \n",
       "25%    1.040000e+02  1.617400e-01 -1.859162e-03 -2.655044e-03 -5.030704e-03   \n",
       "50%    2.540000e+02  7.086770e-01  4.552665e-05  6.928179e-05  1.164734e-04   \n",
       "75%    3.820000e+02  2.471791e+00  2.097469e-03  2.939111e-03  5.466336e-03   \n",
       "max    4.990000e+02  1.672937e+02  2.453477e-01  2.949339e-01  3.265597e-01   \n",
       "\n",
       "             resp_4          resp     feature_0     feature_1     feature_2  \\\n",
       "count  2.390491e+06  2.390491e+06  2.390491e+06  2.390491e+06  2.390491e+06   \n",
       "mean   4.350201e-04  4.083113e-04  9.838565e-03  3.855776e-01  3.576875e-01   \n",
       "std    3.291224e-02  2.693609e-02  9.999518e-01  2.559373e+00  2.477335e+00   \n",
       "min   -5.987447e-01 -5.493845e-01 -1.000000e+00 -3.172026e+00 -3.093182e+00   \n",
       "25%   -9.310415e-03 -7.157903e-03 -1.000000e+00 -1.299334e+00 -1.263628e+00   \n",
       "50%    1.222579e-04  8.634997e-05  1.000000e+00 -1.870182e-05 -7.200577e-07   \n",
       "75%    9.804649e-03  7.544347e-03  1.000000e+00  1.578417e+00  1.526399e+00   \n",
       "max    5.113795e-01  4.484616e-01  1.000000e+00  7.442989e+01  1.480763e+02   \n",
       "\n",
       "       ...   feature_121   feature_122   feature_123   feature_124  \\\n",
       "count  ...  2.320637e+06  2.390268e+06  2.390268e+06  2.374408e+06   \n",
       "mean   ...  2.687757e-01  3.435523e-01  2.799973e-01  3.351537e-01   \n",
       "std    ...  2.174238e+00  2.087842e+00  1.977643e+00  1.742587e+00   \n",
       "min    ... -7.471971e+00 -5.862979e+00 -6.029281e+00 -4.080720e+00   \n",
       "25%    ... -1.123252e+00 -1.114326e+00 -9.512009e-01 -9.133750e-01   \n",
       "50%    ...  0.000000e+00  7.006233e-17  6.054629e-17  4.870826e-17   \n",
       "75%    ...  1.342829e+00  1.405926e+00  1.308625e+00  1.228277e+00   \n",
       "max    ...  1.107771e+02  4.812516e+01  1.276908e+02  6.514517e+01   \n",
       "\n",
       "        feature_125   feature_126   feature_127   feature_128   feature_129  \\\n",
       "count  2.374408e+06  2.381638e+06  2.381638e+06  2.388570e+06  2.388570e+06   \n",
       "mean   2.448752e-01  3.391778e-01  2.323809e-01  3.425608e-01  2.456182e-01   \n",
       "std    2.242853e+00  2.534498e+00  1.795854e+00  2.307130e+00  1.765419e+00   \n",
       "min   -8.136407e+00 -8.215050e+00 -5.765982e+00 -7.024909e+00 -5.282181e+00   \n",
       "25%   -1.212124e+00 -1.452912e+00 -8.993050e-01 -1.278341e+00 -8.544535e-01   \n",
       "50%   -2.558675e-16  1.015055e-16  5.419920e-17  8.563069e-17  4.869529e-17   \n",
       "75%    1.409687e+00  1.767275e+00  1.111491e+00  1.582633e+00  1.125321e+00   \n",
       "max    7.052807e+01  5.872849e+01  6.932221e+01  5.119038e+01  1.164568e+02   \n",
       "\n",
       "              ts_id  \n",
       "count  2.390491e+06  \n",
       "mean   1.195245e+06  \n",
       "std    6.900755e+05  \n",
       "min    0.000000e+00  \n",
       "25%    5.976225e+05  \n",
       "50%    1.195245e+06  \n",
       "75%    1.792868e+06  \n",
       "max    2.390490e+06  \n",
       "\n",
       "[8 rows x 138 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981287, 138)\n",
      "(2390491, 138)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>0.859516</td>\n",
       "      <td>-0.003656</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>-0.017403</td>\n",
       "      <td>-0.028896</td>\n",
       "      <td>-0.021435</td>\n",
       "      <td>1</td>\n",
       "      <td>3.151305</td>\n",
       "      <td>5.467693</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.433699</td>\n",
       "      <td>4.282284</td>\n",
       "      <td>1.621115</td>\n",
       "      <td>4.331030</td>\n",
       "      <td>2.553220</td>\n",
       "      <td>3.799011</td>\n",
       "      <td>2.642943</td>\n",
       "      <td>3.998054</td>\n",
       "      <td>527894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>-0.013542</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>-0.032522</td>\n",
       "      <td>-0.026394</td>\n",
       "      <td>1</td>\n",
       "      <td>2.249176</td>\n",
       "      <td>2.618401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.053416</td>\n",
       "      <td>-0.493276</td>\n",
       "      <td>1.661974</td>\n",
       "      <td>-1.082122</td>\n",
       "      <td>2.427706</td>\n",
       "      <td>-0.756115</td>\n",
       "      <td>2.210572</td>\n",
       "      <td>-0.639075</td>\n",
       "      <td>527895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0.590949</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.004051</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.365888</td>\n",
       "      <td>0.824004</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.702873</td>\n",
       "      <td>4.038753</td>\n",
       "      <td>-0.789767</td>\n",
       "      <td>4.133183</td>\n",
       "      <td>-1.207878</td>\n",
       "      <td>3.402796</td>\n",
       "      <td>-0.928290</td>\n",
       "      <td>3.511141</td>\n",
       "      <td>527896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>-0.003064</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>1</td>\n",
       "      <td>1.514607</td>\n",
       "      <td>0.596214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.304354</td>\n",
       "      <td>1.530169</td>\n",
       "      <td>3.596848</td>\n",
       "      <td>4.613493</td>\n",
       "      <td>4.516110</td>\n",
       "      <td>3.341374</td>\n",
       "      <td>2.635798</td>\n",
       "      <td>1.535235</td>\n",
       "      <td>527897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.158576</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.364269</td>\n",
       "      <td>2.006926</td>\n",
       "      <td>-1.237922</td>\n",
       "      <td>2.124396</td>\n",
       "      <td>-2.005723</td>\n",
       "      <td>1.716914</td>\n",
       "      <td>-1.646484</td>\n",
       "      <td>1.795211</td>\n",
       "      <td>527898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862592</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.649365</td>\n",
       "      <td>-1.169996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.896874</td>\n",
       "      <td>-1.260055</td>\n",
       "      <td>1.947725</td>\n",
       "      <td>-1.994399</td>\n",
       "      <td>-1.685163</td>\n",
       "      <td>-2.866165</td>\n",
       "      <td>-0.216130</td>\n",
       "      <td>-1.892048</td>\n",
       "      <td>0.901585</td>\n",
       "      <td>2390486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862593</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>1</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>5.284504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936553</td>\n",
       "      <td>1.064936</td>\n",
       "      <td>3.119762</td>\n",
       "      <td>-0.419796</td>\n",
       "      <td>-0.208975</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>0.730166</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>2.068737</td>\n",
       "      <td>2390487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862594</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-0.963682</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.956745</td>\n",
       "      <td>-0.640334</td>\n",
       "      <td>-2.279663</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>-4.388417</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.288939</td>\n",
       "      <td>-1.336142</td>\n",
       "      <td>-2.814239</td>\n",
       "      <td>2390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862595</th>\n",
       "      <td>499</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.463757</td>\n",
       "      <td>-1.107228</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.035894</td>\n",
       "      <td>-1.780962</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-2.202140</td>\n",
       "      <td>-1.912601</td>\n",
       "      <td>-3.341684</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-2.185795</td>\n",
       "      <td>0.627452</td>\n",
       "      <td>2390489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862596</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.817184</td>\n",
       "      <td>-1.131577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571013</td>\n",
       "      <td>2.483421</td>\n",
       "      <td>8.284037</td>\n",
       "      <td>-0.698486</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>-0.168395</td>\n",
       "      <td>2.051091</td>\n",
       "      <td>1.726072</td>\n",
       "      <td>5.823676</td>\n",
       "      <td>2390490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1862597 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0          86  0.859516 -0.003656 -0.005449 -0.017403 -0.028896 -0.021435   \n",
       "1          86  0.000000 -0.009107 -0.013542 -0.022222 -0.032522 -0.026394   \n",
       "2          86  0.590949  0.000347 -0.000376 -0.004051 -0.007995 -0.004743   \n",
       "3          86  0.172997  0.000168  0.000333 -0.002375 -0.003064  0.001527   \n",
       "4          86  0.000000  0.000503  0.000589 -0.001587 -0.002665 -0.000139   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "1862592   499  0.000000  0.000142  0.000142  0.005829  0.020342  0.015396   \n",
       "1862593   499  0.000000  0.000012  0.000012 -0.000935 -0.006326 -0.004718   \n",
       "1862594   499  0.000000  0.000499  0.000499  0.007605  0.024907  0.016591   \n",
       "1862595   499  0.283405 -0.000156 -0.000156 -0.001375 -0.003702 -0.002004   \n",
       "1862596   499  0.000000 -0.001855 -0.001855 -0.001194 -0.000864 -0.001905   \n",
       "\n",
       "         feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0                1   3.151305   5.467693  ...          NaN     2.433699   \n",
       "1                1   2.249176   2.618401  ...          NaN     2.053416   \n",
       "2               -1  -0.365888   0.824004  ...          NaN    -0.702873   \n",
       "3                1   1.514607   0.596214  ...          NaN     2.304354   \n",
       "4               -1  -1.158576  -0.146579  ...          NaN    -1.364269   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "1862592          1  -1.649365  -1.169996  ...    -1.896874    -1.260055   \n",
       "1862593          1   2.432943   5.284504  ...    -0.936553     1.064936   \n",
       "1862594          1  -0.622475  -0.963682  ...    -2.956745    -0.640334   \n",
       "1862595         -1  -1.463757  -1.107228  ...    -2.035894    -1.780962   \n",
       "1862596         -1  -1.817184  -1.131577  ...    -0.571013     2.483421   \n",
       "\n",
       "         feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0           4.282284     1.621115     4.331030     2.553220     3.799011   \n",
       "1          -0.493276     1.661974    -1.082122     2.427706    -0.756115   \n",
       "2           4.038753    -0.789767     4.133183    -1.207878     3.402796   \n",
       "3           1.530169     3.596848     4.613493     4.516110     3.341374   \n",
       "4           2.006926    -1.237922     2.124396    -2.005723     1.716914   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1862592     1.947725    -1.994399    -1.685163    -2.866165    -0.216130   \n",
       "1862593     3.119762    -0.419796    -0.208975    -0.146749     0.730166   \n",
       "1862594    -2.279663    -0.950259    -4.388417    -1.669922    -3.288939   \n",
       "1862595     0.881246    -2.202140    -1.912601    -3.341684    -0.571188   \n",
       "1862596     8.284037    -0.698486     0.199953    -0.168395     2.051091   \n",
       "\n",
       "         feature_128  feature_129    ts_id  \n",
       "0           2.642943     3.998054   527894  \n",
       "1           2.210572    -0.639075   527895  \n",
       "2          -0.928290     3.511141   527896  \n",
       "3           2.635798     1.535235   527897  \n",
       "4          -1.646484     1.795211   527898  \n",
       "...              ...          ...      ...  \n",
       "1862592    -1.892048     0.901585  2390486  \n",
       "1862593     0.648452     2.068737  2390487  \n",
       "1862594    -1.336142    -2.814239  2390488  \n",
       "1862595    -2.185795     0.627452  2390489  \n",
       "1862596     1.726072     5.823676  2390490  \n",
       "\n",
       "[1862597 rows x 138 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('date > 85').reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['action'] = (df['resp'] > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-3a52fa01bf43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trades = pd.pivot_table(df, index='date', values='action',\n\u001b[0m\u001b[1;32m      2\u001b[0m            aggfunc={'action':[np.sum, np.mean]},fill_value=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "trades = pd.pivot_table(df, index='date', values='action',\n",
    "           aggfunc={'action':[np.sum, np.mean]},fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5041644241329167"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.std(trades['mean'])\n",
    "trades['mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025218167900784832"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades['mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.12.1-cp38-cp38-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from statsmodels) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.21 in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from statsmodels) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from statsmodels) (1.6.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Collecting patsy>=0.5\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/x99e/anaconda3/envs/kaggle_tf/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.1 statsmodels-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(trades['mean'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trades['mean'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWrElEQVR4nO3df7RdZX3n8fcnNyQk8iNiggKJhmqqxI4EJwt01JZKbYHVwkxnRqFW0aEyrtEunTrTAXWo0q52Ol1abct0pBVRrCLaGSfLSUVlZNnOCHJBsCYxkiKS8CuXHxEQTEjynT/OvunJ5f44yT03957N+7XWWTn72c9+znffe/LZ+z773LtTVUiSBt+82S5AktQfBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5NU5K3JPm7aWz/N0ku6GdNemYy0HVIJLkhySNJFh7ANpXkRTNZ16GW5ANJPt3dVlVnVdUnZ6smtYeBrhmXZCXwGqCAc2a3msklmd9LmzQXGeg6FN4M3AhcBeybWmjO2n+ja3nf1EWSbzTNtyd5PMkbmva3JdmS5OEk65Ic37X9S5N8tVn3QJL3Nu0Lk3wkyb3N4yOjPykkOT3JtiT/Kcn9wCeas+gvJPl0kkeBtyQ5OsnHk9yX5J4kv5dkaLydTfLRJFuTPJrkliSvadrPBN4LvKHZp9vHfh2SzEvy/iQ/TLI9yaeSHN2sW9n81HJBkruTPJjkfdP+7qg1DHQdCm8G/qp5/FKS5061QVX9bPP05Ko6oqo+l+S1wB8ArweOA34IXAOQ5Ejga8CXgeOBFwHXN2O8D3gFsAY4GTgVeH/Xyz0POAZ4AXBR03Yu8AVgSVP3VcDuZtxTgF8EfoPx3dy81jHAZ4DPJzm8qr4M/D7wuWafTh5n27c0j58Hfgo4AvizMX1eDbwYOAO4NMlJE9ShZxgDXTMqyavpBOW1VXUL8A/Arx3kcG8ErqyqW6tqJ3AJ8MpmSueXgfur6kNV9ZOqeqyqbura7rKq2l5VI8AHgTd1jbsX+J2q2llVTzZt36yqL1bVXuAo4Gzg3VX146raDvwxcN54RVbVp6vqoaraXVUfAhbSCeBe9/HDVXVnVT3e7ON5Y6Z9PlhVT1bV7cDtdA5SkoGuGXcB8JWqerBZ/gxd0y4H6Hg6Z+UANIH3EHACsILOwWLK7Zrnx3ctj1TVT8Zss7Xr+QuAw4D7kuxIsgP4GHDseC+W5D8k2ZTkR03fo4Glk+/apLXOB7p/qrm/6/kTdM7iJbzYoxmTZBGd6ZGhZn4aOmerS5KcDPwYWNy1yfOmGPJeOuE6Ov6zgOcA99AJ4HHPmLu229AsP79pGzXenxztbtsK7ASWVtXuyQps5st/m850yIaq2pvkESCTvNZ4tY56Pp2pngeA5VNsq2c4z9A1k/45sAdYTWdOeQ1wEvC3dObVbwN+Ncni5uOJF47Z/gE688ijPgu8Ncma5qLm7wM3VdVdwJeA45K8u7kIemSS07q2e3+SZUmWApcC+310cDJVdR/wFeBDSY5qLly+MMnPjdP9SDoBPALMT3IpnSmb7n1amWSi/3ufBf59khOTHME/zrlPeiCRwEDXzLoA+ERV3V1V948+6FzkeyOdeehddELuk3QuPnb7APDJZprj9VX1NeA/A38N3Ae8kOasvKoeA14H/AqdKYk76FxYBPg9YBj4DvD3wK1N24F4M7AA2Ag8QueC6XHj9LuOzoXZ79OZLvkJ+0/ffL7596Ekt46z/ZXA1cA3gB802//mAdaqZ6h4gwtJagfP0CWpJQx0SWoJA12SWsJAl6SWmLXPoS9durRWrlw5Wy8vSQPplltuebCqlo23btYCfeXKlQwPD8/Wy0vSQEryw4nWOeUiSS1hoEtSSxjoktQSBroktYSBLkktMWWgJ7myuRXWdydYnyR/0twW7DtJXt7/Mjv27C2u3/QAf3L9HVy/6QH27PXv0EjSqF4+tngVnb+O96kJ1p8FrGoepwF/3vzbV3v2Fm/6+E3ctnUHT+7aw6IFQ6xZsYSrLzyNoXmZegBJarkpz9Cr6hvAw5N0ORf4VHXcSOfmBeP9WdFpuWHzdm7buoMndu2hgCd27eG2rTu4YfP2fr+UJA2kfsyhn8D+f+95W9P2NEkuSjKcZHhkZOSAXmTDvY/y5K49+7U9uWsPG+999ADLlaR2OqQXRavqiqpaW1Vrly0b9zdXJ/TS449i0YKh/doWLRhi9fFHTbCFJD2z9CPQ76Fzg95Ry5u2vjr9xceyZsUSRqfLFzdz6Ke/eNz79ErSM04/An0d8Obm0y6vAH7U3IOxr4bmhasvPI0XHXsEy5cs4k/PP8ULopLUZcpPuST5LHA6sDTJNuB3gMMAquq/A+uBs4EtwBPAW2eq2KF54dmLF/DsxXDGSc+dqZeRpIE0ZaBX1flTrC/gHX2rSJJ0UPxNUUlqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJboKdCTnJlkc5ItSS4eZ/3zk3w9ybeTfCfJ2f0vVZI0mSkDPckQcDlwFrAaOD/J6jHd3g9cW1WnAOcB/63fhUqSJtfLGfqpwJaqurOqdgHXAOeO6VPAUc3zo4F7+1eiJKkXvQT6CcDWruVtTVu3DwC/nmQbsB74zfEGSnJRkuEkwyMjIwdRriRpIv26KHo+cFVVLQfOBq5O8rSxq+qKqlpbVWuXLVvWp5eWJEFvgX4PsKJreXnT1u1C4FqAqvomcDiwtB8FSpJ600ug3wysSnJikgV0LnquG9PnbuAMgCQn0Ql051Qk6RCaMtCrajfwTuA6YBOdT7NsSHJZknOabu8B3pbkduCzwFuqqmaqaEnS083vpVNVradzsbO77dKu5xuBV/W3NEnSgfA3RSWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqiZ4CPcmZSTYn2ZLk4gn6vD7JxiQbknymv2VKkqYyf6oOSYaAy4HXAduAm5Osq6qNXX1WAZcAr6qqR5IcO1MFS5LG18sZ+qnAlqq6s6p2AdcA547p8zbg8qp6BKCqtve3TEnSVHoJ9BOArV3L25q2bj8N/HSS/5vkxiRnjjdQkouSDCcZHhkZObiKJUnj6tdF0fnAKuB04HzgL5IsGdupqq6oqrVVtXbZsmV9emlJEvQW6PcAK7qWlzdt3bYB66rqqar6AfB9OgEvSTpEegn0m4FVSU5MsgA4D1g3ps8X6Zydk2QpnSmYO/tXpiRpKlMGelXtBt4JXAdsAq6tqg1JLktyTtPtOuChJBuBrwP/saoemqmiJUlPN+XHFgGqaj2wfkzbpV3PC/it5iFJmgX+pqgktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JL9BToSc5MsjnJliQXT9LvXyapJGv7V6IkqRdTBnqSIeBy4CxgNXB+ktXj9DsSeBdwU7+LlCRNrZcz9FOBLVV1Z1XtAq4Bzh2n3+8Cfwj8pI/1SZJ61EugnwBs7Vre1rTtk+TlwIqq+t+TDZTkoiTDSYZHRkYOuFhJ0sSmfVE0yTzgw8B7pupbVVdU1dqqWrts2bLpvrQkqUsvgX4PsKJreXnTNupI4GeAG5LcBbwCWOeFUUk6tHoJ9JuBVUlOTLIAOA9YN7qyqn5UVUuramVVrQRuBM6pquEZqViSNK4pA72qdgPvBK4DNgHXVtWGJJclOWemC5Qk9WZ+L52qaj2wfkzbpRP0PX36ZUmSDpS/KSpJLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSS/QU6EnOTLI5yZYkF4+z/reSbEzynSTXJ3lB/0uVJE1mykBPMgRcDpwFrAbOT7J6TLdvA2ur6mXAF4D/2u9CJUmT6+UM/VRgS1XdWVW7gGuAc7s7VNXXq+qJZvFGYHl/y5QkTaWXQD8B2Nq1vK1pm8iFwN+MtyLJRUmGkwyPjIz0XqUkaUp9vSia5NeBtcAfjbe+qq6oqrVVtXbZsmX9fGlJesab30Ofe4AVXcvLm7b9JPkF4H3Az1XVzv6UJ0nqVS9n6DcDq5KcmGQBcB6wrrtDklOAjwHnVNX2/pcpSZrKlIFeVbuBdwLXAZuAa6tqQ5LLkpzTdPsj4Ajg80luS7JuguEkSTOklykXqmo9sH5M26Vdz3+hz3VJkg6QvykqSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSS8yf7QKma8/e4obN29lw76O89PijOP3FxzI0L7NdliQdcgMd6Hv2Fm/6+E3ctnUHT+7aw6IFQ6xZsYSr3noqf3vHiCEv6RlloAP9hs3buW3rDp7YtQeAJ3bt4dt3P8K5f/Z3/PDhJ/aF/MnLj+bfvPpENt332L6AH93e0JfUFgMd6BvufZQnmzAf9eRTe9ky8jhP7SmgE/I3/eBhbr17B7t2790X8El6OrOH/YP/NauWTdmnn9vN1bGmU8PYA+d402YHW8N4B+VepuUGeepukGuHwa9/LhnoQH/p8UexaMHQvjN0gMOGwu4mzEftLdi5ey/QCfhb794B7N820Zl9d/Afftg8Fsyfx1N7asI+/dxuro41nRrGHjhPet6RfOL/3dWX2sc7KL9m1TLe8olvHXANM32A79dY06l9LuzPeN+fXn+insn9memvw0wdsFJVU3dKzgQ+CgwBf1lV/2XM+oXAp4B/CjwEvKGq7ppszLVr19bw8PABF/yGj30TgM/921fum0O/8c6H2FuweMEQzz9mMXc//MR+Id+rw4ay78weYOH8zoeARoN/POP16ed2c3Wsg91u0WHzWPmcZ+07cHZCeS9768DHGmvs2IsmeD/0UsN4Y83Fg+vB1j5X9me878+8wGFD8yb9iXqunrD0euJx9YWnHXSoJ7mlqtaOu26qQE8yBHwfeB2wDbgZOL+qNnb1+XfAy6rq7UnOA/5FVb1hsnH7EejQ+XHtrI9+gyd27uGD57503xF/NOQX9hgYo2f2Ux/eNF1jD5wzOfZE39deapjJA/xMHlx7rX0u7E8v/+/mwte0nzUsXjDEn55/Cmec9NwJ+0xmuoH+SuADVfVLzfIlAFX1B119rmv6fDPJfOB+YFlNMvgxLzipXvfeKw94Zzbe9ygAq487ir1VPLWnuGP7YwCsOvZImtr43v2PsbeKE5Ys4sHHd/L4zs4ZwLx0zmCS7Ne2YGgeu8YE/+jxc7Kv0Hh9+rndXB1rOjVMFeXTqaGXw0SvNQzqwX2Qa3+mWL5kESc8e9FBbXvt2//ZhIHeyxz6CcDWruVtwGkT9amq3Ul+BDwHeLC7U5KLgIsAjjjuhT0VP9bq447a93xewsL54WeOP/pp/dasWLLv+bFHLmTHk0/xxM49LF44xJJFhwHs13b04fPZ/MDjPL5zN3urE/LPWjAECT9u2kKnvWDCPv3cbq6ONZ0aFs6fx87d+x844R9DaDo1jDd2gMMPG2Ln7j0HVMNEY8HcPLgeTO1zZX+6vz/jHYwG7YRlqrHmBRYvHJqkx8E7pBdFq+oK4AroTLmMTpvMFaNX2zfe+yirx1zgGG0bvcAxWZ9+bjdXx5rOdhNdBPvefY9Nq4apLoAeSA0T9ZntOeeJ2g609rmyP2O/Py85yIvkz6Q59GvfPvG6WZtyOdg5dA2+8Q6c/brq3+vYvfSbyQN8v8c6mNrnyv70q/a5cMLS61jTeb9Pdw59Pp2LomcA99C5KPprVbWhq887gH/SdVH0V6vq9ZONa6BL0oGbLNCnnHJp5sTfCVxH52OLV1bVhiSXAcNVtQ74OHB1ki3Aw8B5/StfktSLnubQq2o9sH5M26Vdz38C/Ov+liZJOhD++VxJagkDXZJawkCXpJYw0CWpJXr641wz8sLJCPDDg9x8KWN+C3WADHLtMNj1W/vssPb+ekFVLRtvxawF+nQkGZ7oc5hz3SDXDoNdv7XPDms/dJxykaSWMNAlqSUGNdCvmO0CpmGQa4fBrt/aZ4e1HyIDOYcuSXq6QT1DlySNYaBLUksMXKAnOTPJ5iRbklw82/VMJsmVSbYn+W5X2zFJvprkjubfZ89mjRNJsiLJ15NsTLIhybua9jlff5LDk3wrye1N7R9s2k9MclPz3vlckgWzXetEkgwl+XaSLzXLg1T7XUn+PsltSYabtjn/vgFIsiTJF5J8L8mmJK8clNphwAK9uWH15cBZwGrg/CSrZ7eqSV0FnDmm7WLg+qpaBVzfLM9Fu4H3VNVq4BXAO5qv9SDUvxN4bVWdDKwBzkzyCuAPgT+uqhcBjwAXzl6JU3oXsKlreZBqB/j5qlrT9RnuQXjfAHwU+HJVvQQ4mc73YFBq79xQeVAewCuB67qWLwEume26pqh5JfDdruXNwHHN8+OAzbNdY4/78b+A1w1a/cBi4FY698F9EJg/3ntpLj2A5XSC47XAl+jcqnIgam/quwtYOqZtzr9vgKOBH9B8WGSQah99DNQZOuPfsPqEWarlYD23qu5rnt8PPHc2i+lFkpXAKcBNDEj9zZTFbcB24KvAPwA7qmp302Uuv3c+Avw2sLdZfg6DUzt07pH8lSS3NDeGh8F435wIjACfaKa7/jLJsxiM2oEBm3Jpm+oc8uf050aTHAH8NfDuqnq0e91crr+q9lTVGjpnu6cCL5ndinqT5JeB7VV1y2zXMg2vrqqX05kafUeSn+1eOYffN/OBlwN/XlWnAD9mzPTKHK4dGLxAvwdY0bW8vGkbJA8kOQ6g+Xf7LNczoSSH0Qnzv6qq/9E0D0z9AFW1A/g6nWmKJc09cmHuvndeBZyT5C7gGjrTLh9lMGoHoKruaf7dDvxPOgfUQXjfbAO2VdVNzfIX6AT8INQODF6g3wysaq74L6Bz79J1s1zTgVoHXNA8v4DO3PSckyR07hW7qao+3LVqztefZFmSJc3zRXTm/jfRCfZ/1XSbk7VX1SVVtbyqVtJ5f/+fqnojA1A7QJJnJTly9Dnwi8B3GYD3TVXdD2xN8uKm6QxgIwNQ+z6zPYl/EBcuzga+T2dO9H2zXc8UtX4WuA94is7R/0I686HXA3cAXwOOme06J6j91XR+tPwOcFvzOHsQ6gdeBny7qf27wKVN+08B3wK2AJ8HFs52rVPsx+nAlwap9qbO25vHhtH/o4PwvmnqXAMMN++dLwLPHpTaq8pf/Zekthi0KRdJ0gQMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJa4v8DSn1jRwrSVtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acf(df['action'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels' has no attribute 'tsa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-c733ea7ff881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels' has no attribute 'tsa'"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "acf = statsmodels.tsa.stattools.acf(train['action'], fft =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02387651985232728"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['action'].autocorr(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_acf = [train['action'].autocorr(i) for i in range(1,32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012150257495777384,\n",
       " 0.014863162028431274,\n",
       " 0.013626677663840698,\n",
       " 0.012121631780674172,\n",
       " 0.010228395123595026,\n",
       " 0.010167945037171828,\n",
       " 0.009098181712513915,\n",
       " 0.010367771511209753,\n",
       " 0.008759629952437578,\n",
       " 0.007054755570613224,\n",
       " 0.007635781468187949,\n",
       " 0.00762878604873154,\n",
       " 0.009095665016192746,\n",
       " 0.00662202943031397,\n",
       " 0.0072743320693831074,\n",
       " 0.007380607847204211,\n",
       " 0.006602308141266375,\n",
       " 0.007141340426825501,\n",
       " 0.005396993214397279,\n",
       " 0.008149386600898138,\n",
       " 0.007189071705626117,\n",
       " 0.005165987508430664,\n",
       " 0.006303217391923997,\n",
       " 0.006784970410215175,\n",
       " 0.004982079814075244,\n",
       " 0.007140086414810789,\n",
       " 0.006259958619565094,\n",
       " 0.005896581626518581,\n",
       " 0.005783937724186868,\n",
       " 0.00550456406570725,\n",
       " 0.005068642673217722]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "SEED = 1111\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train = dt.fread('~/jane-street-market-prediction/train.csv').to_pandas()\n",
    "\n",
    "\n",
    "#train = pd.read_csv('~/jane-street-market-prediction/train.csv')\n",
    "train = train.query('date > 85').reset_index(drop = True) \n",
    "train = train[train['weight'] != 0]\n",
    "\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "\n",
    "train['action'] = ((train['resp'].values) > 0).astype(int)\n",
    "\n",
    "\n",
    "features = [c for c in train.columns if \"feature\" in c]\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "y_train = (train.loc[:, 'action'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x) #(x)\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "        #x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, inp])\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp2(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    #x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x) #(x)\n",
    "    \n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        #x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, inp])\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "315/315 [==============================] - 6s 10ms/step - loss: 0.7498 - AUC: 0.5052\n",
      "Epoch 2/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6965 - AUC: 0.5150\n",
      "Epoch 3/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6928 - AUC: 0.5222\n",
      "Epoch 4/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6918 - AUC: 0.5281\n",
      "Epoch 5/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6916 - AUC: 0.5303\n",
      "Epoch 6/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6913 - AUC: 0.5323\n",
      "Epoch 7/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6910 - AUC: 0.5343\n",
      "Epoch 8/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6909 - AUC: 0.5349\n",
      "Epoch 9/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6908 - AUC: 0.5352\n",
      "Epoch 10/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6903 - AUC: 0.5381\n",
      "Epoch 11/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6902 - AUC: 0.5388\n",
      "Epoch 12/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6900 - AUC: 0.5403\n",
      "Epoch 13/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6897 - AUC: 0.5415\n",
      "Epoch 14/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6896 - AUC: 0.5420\n",
      "Epoch 15/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6892 - AUC: 0.5435\n",
      "Epoch 16/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6889 - AUC: 0.5445\n",
      "Epoch 17/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6885 - AUC: 0.5471\n",
      "Epoch 18/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6881 - AUC: 0.5479\n",
      "Epoch 19/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6878 - AUC: 0.5497\n",
      "Epoch 20/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6876 - AUC: 0.5499\n",
      "Epoch 21/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6872 - AUC: 0.5511\n",
      "Epoch 22/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6869 - AUC: 0.5522\n",
      "Epoch 23/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6866 - AUC: 0.5531\n",
      "Epoch 24/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6862 - AUC: 0.5543\n",
      "Epoch 25/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6861 - AUC: 0.5537\n",
      "Epoch 26/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6858 - AUC: 0.5548\n",
      "Epoch 27/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6855 - AUC: 0.5555\n",
      "Epoch 28/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6852 - AUC: 0.5570\n",
      "Epoch 29/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6849 - AUC: 0.5574\n",
      "Epoch 30/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6846 - AUC: 0.5590\n",
      "Epoch 31/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6845 - AUC: 0.5590\n",
      "Epoch 32/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6843 - AUC: 0.5597\n",
      "Epoch 33/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6839 - AUC: 0.5602\n",
      "Epoch 34/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6839 - AUC: 0.5602\n",
      "Epoch 35/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6836 - AUC: 0.5607\n",
      "Epoch 36/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6833 - AUC: 0.5614\n",
      "Epoch 37/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6832 - AUC: 0.5621\n",
      "Epoch 38/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6829 - AUC: 0.5631\n",
      "Epoch 39/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6828 - AUC: 0.5635\n",
      "Epoch 40/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6825 - AUC: 0.5643\n",
      "Epoch 41/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6822 - AUC: 0.5647\n",
      "Epoch 42/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6820 - AUC: 0.5661\n",
      "Epoch 43/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6819 - AUC: 0.5659\n",
      "Epoch 44/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6819 - AUC: 0.5661\n",
      "Epoch 45/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6816 - AUC: 0.5664\n",
      "Epoch 46/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6815 - AUC: 0.5668\n",
      "Epoch 47/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6813 - AUC: 0.5670\n",
      "Epoch 48/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6812 - AUC: 0.5665\n",
      "Epoch 49/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6809 - AUC: 0.5681\n",
      "Epoch 50/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6809 - AUC: 0.5681\n",
      "Epoch 51/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6808 - AUC: 0.5689\n",
      "Epoch 52/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6806 - AUC: 0.5685\n",
      "Epoch 53/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6807 - AUC: 0.5688\n",
      "Epoch 54/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6804 - AUC: 0.5691\n",
      "Epoch 55/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6804 - AUC: 0.5695\n",
      "Epoch 56/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6801 - AUC: 0.5705\n",
      "Epoch 57/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6801 - AUC: 0.5705\n",
      "Epoch 58/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6800 - AUC: 0.5698\n",
      "Epoch 59/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6802 - AUC: 0.5697\n",
      "Epoch 60/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6795 - AUC: 0.5721\n",
      "Epoch 61/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6796 - AUC: 0.5706\n",
      "Epoch 62/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6797 - AUC: 0.5706\n",
      "Epoch 63/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6794 - AUC: 0.5714\n",
      "Epoch 64/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6792 - AUC: 0.5725\n",
      "Epoch 65/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6793 - AUC: 0.5718\n",
      "Epoch 66/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6792 - AUC: 0.5725\n",
      "Epoch 67/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6791 - AUC: 0.5726\n",
      "Epoch 68/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6791 - AUC: 0.5730\n",
      "Epoch 69/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6789 - AUC: 0.5731\n",
      "Epoch 70/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6787 - AUC: 0.5735\n",
      "Epoch 71/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6787 - AUC: 0.5734\n",
      "Epoch 72/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6784 - AUC: 0.5741\n",
      "Epoch 73/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6787 - AUC: 0.5736\n",
      "Epoch 74/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6784 - AUC: 0.5747\n",
      "Epoch 75/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6784 - AUC: 0.5745\n",
      "Epoch 76/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6785 - AUC: 0.5738\n",
      "Epoch 77/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6784 - AUC: 0.5749\n",
      "Epoch 78/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6785 - AUC: 0.5746\n",
      "Epoch 79/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6779 - AUC: 0.5757\n",
      "Epoch 80/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6782 - AUC: 0.5743\n",
      "Epoch 81/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6780 - AUC: 0.5753\n",
      "Epoch 82/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6779 - AUC: 0.5757\n",
      "Epoch 83/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6779 - AUC: 0.5764\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6779 - AUC: 0.5762\n",
      "Epoch 85/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6777 - AUC: 0.5754\n",
      "Epoch 86/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6775 - AUC: 0.5767\n",
      "Epoch 87/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6774 - AUC: 0.5768\n",
      "Epoch 88/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6773 - AUC: 0.5765\n",
      "Epoch 89/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6775 - AUC: 0.5766\n",
      "Epoch 90/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6773 - AUC: 0.5773\n",
      "Epoch 91/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6775 - AUC: 0.5761\n",
      "Epoch 92/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6774 - AUC: 0.5766\n",
      "Epoch 93/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6769 - AUC: 0.5779\n",
      "Epoch 94/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6773 - AUC: 0.5767\n",
      "Epoch 95/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6773 - AUC: 0.5767\n",
      "Epoch 96/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6771 - AUC: 0.5769\n",
      "Epoch 97/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6770 - AUC: 0.5777\n",
      "Epoch 98/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6768 - AUC: 0.5777\n",
      "Epoch 99/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6770 - AUC: 0.5786\n",
      "Epoch 100/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6769 - AUC: 0.5781\n",
      "Epoch 101/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6769 - AUC: 0.5784\n",
      "Epoch 102/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6767 - AUC: 0.5785\n",
      "Epoch 103/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6764 - AUC: 0.5784\n",
      "Epoch 104/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6762 - AUC: 0.5792\n",
      "Epoch 105/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6767 - AUC: 0.5786\n",
      "Epoch 106/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6765 - AUC: 0.5786\n",
      "Epoch 107/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6764 - AUC: 0.5786\n",
      "Epoch 108/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6762 - AUC: 0.5797\n",
      "Epoch 109/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6763 - AUC: 0.5795\n",
      "Epoch 110/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6765 - AUC: 0.5791\n",
      "Epoch 111/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6759 - AUC: 0.5805\n",
      "Epoch 112/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6762 - AUC: 0.5795\n",
      "Epoch 113/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6762 - AUC: 0.5796\n",
      "Epoch 114/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6764 - AUC: 0.5785\n",
      "Epoch 115/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6760 - AUC: 0.5807\n",
      "Epoch 116/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6761 - AUC: 0.5800\n",
      "Epoch 117/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6760 - AUC: 0.5797\n",
      "Epoch 118/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6761 - AUC: 0.5799\n",
      "Epoch 119/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6759 - AUC: 0.5801\n",
      "Epoch 120/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6758 - AUC: 0.5813\n",
      "Epoch 121/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6758 - AUC: 0.5808\n",
      "Epoch 122/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6760 - AUC: 0.5802\n",
      "Epoch 123/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6762 - AUC: 0.5796\n",
      "Epoch 124/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6758 - AUC: 0.5809\n",
      "Epoch 125/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6756 - AUC: 0.5816\n",
      "Epoch 126/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6759 - AUC: 0.5803\n",
      "Epoch 127/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6754 - AUC: 0.5820\n",
      "Epoch 128/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6755 - AUC: 0.5818\n",
      "Epoch 129/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6759 - AUC: 0.5814\n",
      "Epoch 130/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6755 - AUC: 0.5809\n",
      "Epoch 131/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6757 - AUC: 0.5804\n",
      "Epoch 132/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6753 - AUC: 0.5812\n",
      "Epoch 133/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6754 - AUC: 0.5819\n",
      "Epoch 134/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6754 - AUC: 0.5818\n",
      "Epoch 135/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6755 - AUC: 0.5813\n",
      "Epoch 136/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6756 - AUC: 0.5810\n",
      "Epoch 137/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6754 - AUC: 0.5821\n",
      "Epoch 138/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6754 - AUC: 0.5818\n",
      "Epoch 139/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6753 - AUC: 0.5816\n",
      "Epoch 140/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6753 - AUC: 0.5823\n",
      "Epoch 141/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6751 - AUC: 0.5821\n",
      "Epoch 142/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6751 - AUC: 0.5826\n",
      "Epoch 143/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6752 - AUC: 0.5822\n",
      "Epoch 144/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6749 - AUC: 0.5829\n",
      "Epoch 145/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6750 - AUC: 0.5823\n",
      "Epoch 146/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6752 - AUC: 0.5822\n",
      "Epoch 147/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6749 - AUC: 0.5821\n",
      "Epoch 148/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6751 - AUC: 0.5827\n",
      "Epoch 149/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6750 - AUC: 0.5832\n",
      "Epoch 150/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6751 - AUC: 0.5826\n",
      "Epoch 151/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6750 - AUC: 0.5825\n",
      "Epoch 152/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5839\n",
      "Epoch 153/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6748 - AUC: 0.5837\n",
      "Epoch 154/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5835\n",
      "Epoch 155/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5835\n",
      "Epoch 156/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6749 - AUC: 0.5827\n",
      "Epoch 157/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6748 - AUC: 0.5828\n",
      "Epoch 158/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6747 - AUC: 0.5840\n",
      "Epoch 159/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5833\n",
      "Epoch 160/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6745 - AUC: 0.5840\n",
      "Epoch 161/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5828\n",
      "Epoch 162/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5836\n",
      "Epoch 163/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5839\n",
      "Epoch 164/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5847\n",
      "Epoch 165/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6744 - AUC: 0.5843\n",
      "Epoch 166/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6745 - AUC: 0.5841\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6743 - AUC: 0.5841\n",
      "Epoch 168/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6741 - AUC: 0.5845\n",
      "Epoch 169/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5841\n",
      "Epoch 170/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6743 - AUC: 0.5841\n",
      "Epoch 171/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6746 - AUC: 0.5836\n",
      "Epoch 172/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6745 - AUC: 0.5837\n",
      "Epoch 173/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5847\n",
      "Epoch 174/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6743 - AUC: 0.5839\n",
      "Epoch 175/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5848\n",
      "Epoch 176/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6741 - AUC: 0.5847\n",
      "Epoch 177/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6743 - AUC: 0.5839\n",
      "Epoch 178/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5847\n",
      "Epoch 179/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5845\n",
      "Epoch 180/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5836\n",
      "Epoch 181/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5849\n",
      "Epoch 182/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6737 - AUC: 0.5856\n",
      "Epoch 183/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6738 - AUC: 0.5857\n",
      "Epoch 184/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5855\n",
      "Epoch 185/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6740 - AUC: 0.5848\n",
      "Epoch 186/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6740 - AUC: 0.5852\n",
      "Epoch 187/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6741 - AUC: 0.5845\n",
      "Epoch 188/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5854\n",
      "Epoch 189/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6740 - AUC: 0.5850\n",
      "Epoch 190/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5860\n",
      "Epoch 191/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6741 - AUC: 0.5845\n",
      "Epoch 192/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5847\n",
      "Epoch 193/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6736 - AUC: 0.5858\n",
      "Epoch 194/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6738 - AUC: 0.5858\n",
      "Epoch 195/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6736 - AUC: 0.5865\n",
      "Epoch 196/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6738 - AUC: 0.5856\n",
      "Epoch 197/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6736 - AUC: 0.5859\n",
      "Epoch 198/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6736 - AUC: 0.5862\n",
      "Epoch 199/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6742 - AUC: 0.5845\n",
      "Epoch 200/200\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.6739 - AUC: 0.5854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 5000\n",
    "hidden_units = [130, 130, 130]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "clf = create_mlp(\n",
    "    len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train, epochs=200, batch_size=5000)\n",
    "\n",
    "opt_th = 0.5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "158/158 [==============================] - 4s 14ms/step - loss: 0.7754 - AUC: 0.5039\n",
      "Epoch 2/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.7028 - AUC: 0.5114\n",
      "Epoch 3/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6964 - AUC: 0.5156\n",
      "Epoch 4/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6934 - AUC: 0.5212\n",
      "Epoch 5/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6924 - AUC: 0.5253\n",
      "Epoch 6/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6918 - AUC: 0.5288\n",
      "Epoch 7/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6915 - AUC: 0.5304\n",
      "Epoch 8/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6914 - AUC: 0.5311\n",
      "Epoch 9/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6913 - AUC: 0.5316\n",
      "Epoch 10/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6910 - AUC: 0.5341\n",
      "Epoch 11/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6909 - AUC: 0.5354\n",
      "Epoch 12/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6908 - AUC: 0.5352\n",
      "Epoch 13/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6905 - AUC: 0.5364\n",
      "Epoch 14/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6905 - AUC: 0.5364\n",
      "Epoch 15/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6903 - AUC: 0.5381\n",
      "Epoch 16/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6901 - AUC: 0.5388\n",
      "Epoch 17/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6899 - AUC: 0.5400\n",
      "Epoch 18/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6897 - AUC: 0.5405\n",
      "Epoch 19/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6896 - AUC: 0.5420\n",
      "Epoch 20/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6894 - AUC: 0.5416\n",
      "Epoch 21/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6890 - AUC: 0.5434\n",
      "Epoch 22/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6889 - AUC: 0.5439\n",
      "Epoch 23/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6887 - AUC: 0.5447\n",
      "Epoch 24/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6883 - AUC: 0.5458\n",
      "Epoch 25/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6881 - AUC: 0.5461\n",
      "Epoch 26/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6879 - AUC: 0.5472\n",
      "Epoch 27/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6877 - AUC: 0.5482\n",
      "Epoch 28/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6875 - AUC: 0.5487\n",
      "Epoch 29/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6871 - AUC: 0.5497\n",
      "Epoch 30/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6869 - AUC: 0.5510\n",
      "Epoch 31/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6868 - AUC: 0.5508\n",
      "Epoch 32/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6867 - AUC: 0.5514\n",
      "Epoch 33/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6863 - AUC: 0.5523\n",
      "Epoch 34/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6862 - AUC: 0.5523\n",
      "Epoch 35/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6859 - AUC: 0.5533\n",
      "Epoch 36/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6859 - AUC: 0.5530\n",
      "Epoch 37/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6855 - AUC: 0.5550\n",
      "Epoch 38/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6853 - AUC: 0.5553\n",
      "Epoch 39/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6854 - AUC: 0.5550\n",
      "Epoch 40/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6850 - AUC: 0.5559\n",
      "Epoch 41/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6847 - AUC: 0.5568\n",
      "Epoch 42/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6847 - AUC: 0.5572\n",
      "Epoch 43/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6844 - AUC: 0.5572\n",
      "Epoch 44/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6845 - AUC: 0.5580\n",
      "Epoch 45/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6843 - AUC: 0.5576\n",
      "Epoch 46/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6839 - AUC: 0.5591\n",
      "Epoch 47/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6838 - AUC: 0.5594\n",
      "Epoch 48/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6837 - AUC: 0.5594\n",
      "Epoch 49/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6837 - AUC: 0.5597\n",
      "Epoch 50/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6836 - AUC: 0.5599\n",
      "Epoch 51/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6833 - AUC: 0.5608\n",
      "Epoch 52/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6833 - AUC: 0.5608\n",
      "Epoch 53/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6831 - AUC: 0.5608\n",
      "Epoch 54/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6829 - AUC: 0.5619\n",
      "Epoch 55/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6828 - AUC: 0.5619\n",
      "Epoch 56/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6826 - AUC: 0.5630\n",
      "Epoch 57/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6826 - AUC: 0.5629\n",
      "Epoch 58/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6824 - AUC: 0.5629\n",
      "Epoch 59/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6824 - AUC: 0.5629\n",
      "Epoch 60/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6821 - AUC: 0.5635\n",
      "Epoch 61/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6821 - AUC: 0.5638\n",
      "Epoch 62/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6820 - AUC: 0.5646\n",
      "Epoch 63/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6820 - AUC: 0.5641\n",
      "Epoch 64/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6818 - AUC: 0.5643\n",
      "Epoch 65/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6820 - AUC: 0.5641\n",
      "Epoch 66/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6815 - AUC: 0.5658\n",
      "Epoch 67/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6813 - AUC: 0.5657\n",
      "Epoch 68/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6812 - AUC: 0.5660\n",
      "Epoch 69/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6813 - AUC: 0.5651\n",
      "Epoch 70/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6812 - AUC: 0.5665\n",
      "Epoch 71/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6811 - AUC: 0.5662\n",
      "Epoch 72/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6808 - AUC: 0.5675\n",
      "Epoch 73/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6810 - AUC: 0.5664\n",
      "Epoch 74/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6808 - AUC: 0.5672\n",
      "Epoch 75/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6806 - AUC: 0.5674\n",
      "Epoch 76/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6807 - AUC: 0.5667\n",
      "Epoch 77/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6804 - AUC: 0.5679\n",
      "Epoch 78/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6806 - AUC: 0.5681\n",
      "Epoch 79/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6800 - AUC: 0.5695\n",
      "Epoch 80/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6804 - AUC: 0.5677\n",
      "Epoch 81/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6804 - AUC: 0.5679\n",
      "Epoch 82/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6802 - AUC: 0.5689\n",
      "Epoch 83/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6800 - AUC: 0.5692\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6802 - AUC: 0.5686\n",
      "Epoch 85/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6798 - AUC: 0.5695\n",
      "Epoch 86/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6798 - AUC: 0.5700\n",
      "Epoch 87/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6796 - AUC: 0.5698\n",
      "Epoch 88/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6795 - AUC: 0.5699\n",
      "Epoch 89/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6794 - AUC: 0.5706\n",
      "Epoch 90/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6796 - AUC: 0.5706\n",
      "Epoch 91/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6795 - AUC: 0.5705\n",
      "Epoch 92/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6795 - AUC: 0.5704\n",
      "Epoch 93/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6792 - AUC: 0.5708\n",
      "Epoch 94/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6794 - AUC: 0.5700\n",
      "Epoch 95/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6791 - AUC: 0.5717\n",
      "Epoch 96/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6792 - AUC: 0.5706\n",
      "Epoch 97/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6789 - AUC: 0.5709\n",
      "Epoch 98/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6790 - AUC: 0.5711\n",
      "Epoch 99/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6788 - AUC: 0.5726\n",
      "Epoch 100/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6789 - AUC: 0.5719\n",
      "Epoch 101/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6789 - AUC: 0.5725\n",
      "Epoch 102/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6786 - AUC: 0.5731\n",
      "Epoch 103/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6784 - AUC: 0.5730\n",
      "Epoch 104/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6783 - AUC: 0.5734\n",
      "Epoch 105/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6785 - AUC: 0.5730\n",
      "Epoch 106/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6782 - AUC: 0.5738\n",
      "Epoch 107/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6781 - AUC: 0.5736\n",
      "Epoch 108/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6783 - AUC: 0.5733\n",
      "Epoch 109/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6781 - AUC: 0.5736\n",
      "Epoch 110/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6783 - AUC: 0.5727\n",
      "Epoch 111/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6781 - AUC: 0.5731\n",
      "Epoch 112/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6782 - AUC: 0.5733\n",
      "Epoch 113/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6781 - AUC: 0.5741\n",
      "Epoch 114/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6779 - AUC: 0.5739\n",
      "Epoch 115/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6779 - AUC: 0.5743\n",
      "Epoch 116/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6779 - AUC: 0.5740\n",
      "Epoch 117/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6777 - AUC: 0.5746\n",
      "Epoch 118/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6776 - AUC: 0.5749\n",
      "Epoch 119/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6777 - AUC: 0.5754\n",
      "Epoch 120/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6774 - AUC: 0.5759\n",
      "Epoch 121/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6774 - AUC: 0.5755\n",
      "Epoch 122/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6775 - AUC: 0.5759\n",
      "Epoch 123/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6776 - AUC: 0.5746\n",
      "Epoch 124/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6773 - AUC: 0.5752\n",
      "Epoch 125/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6774 - AUC: 0.5751\n",
      "Epoch 126/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6774 - AUC: 0.5756\n",
      "Epoch 127/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6773 - AUC: 0.5757\n",
      "Epoch 128/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6771 - AUC: 0.5761\n",
      "Epoch 129/200\n",
      "158/158 [==============================] - 2s 15ms/step - loss: 0.6774 - AUC: 0.5756\n",
      "Epoch 130/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6772 - AUC: 0.5766\n",
      "Epoch 131/200\n",
      "158/158 [==============================] - 2s 15ms/step - loss: 0.6772 - AUC: 0.5761\n",
      "Epoch 132/200\n",
      "158/158 [==============================] - 2s 15ms/step - loss: 0.6770 - AUC: 0.5768\n",
      "Epoch 133/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6769 - AUC: 0.5768\n",
      "Epoch 134/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6770 - AUC: 0.5769\n",
      "Epoch 135/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6770 - AUC: 0.5764\n",
      "Epoch 136/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6769 - AUC: 0.5760\n",
      "Epoch 137/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6769 - AUC: 0.5771\n",
      "Epoch 138/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6768 - AUC: 0.5774\n",
      "Epoch 139/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6768 - AUC: 0.5768\n",
      "Epoch 140/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6763 - AUC: 0.5780\n",
      "Epoch 141/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6767 - AUC: 0.5772\n",
      "Epoch 142/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6767 - AUC: 0.5777\n",
      "Epoch 143/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6766 - AUC: 0.5783\n",
      "Epoch 144/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6765 - AUC: 0.5781\n",
      "Epoch 145/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6764 - AUC: 0.5785\n",
      "Epoch 146/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6766 - AUC: 0.5778\n",
      "Epoch 147/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6760 - AUC: 0.5791\n",
      "Epoch 148/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6763 - AUC: 0.5782\n",
      "Epoch 149/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6763 - AUC: 0.5779\n",
      "Epoch 150/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6764 - AUC: 0.5778\n",
      "Epoch 151/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6762 - AUC: 0.5783\n",
      "Epoch 152/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6760 - AUC: 0.5789\n",
      "Epoch 153/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6757 - AUC: 0.5795\n",
      "Epoch 154/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6759 - AUC: 0.5794\n",
      "Epoch 155/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6762 - AUC: 0.5789\n",
      "Epoch 156/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6759 - AUC: 0.5792\n",
      "Epoch 157/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6761 - AUC: 0.5784\n",
      "Epoch 158/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6760 - AUC: 0.5790\n",
      "Epoch 159/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6759 - AUC: 0.5791\n",
      "Epoch 160/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6759 - AUC: 0.5797\n",
      "Epoch 161/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6760 - AUC: 0.5789\n",
      "Epoch 162/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6757 - AUC: 0.5802\n",
      "Epoch 163/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6756 - AUC: 0.5799\n",
      "Epoch 164/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6756 - AUC: 0.5803\n",
      "Epoch 165/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6757 - AUC: 0.5794\n",
      "Epoch 166/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6755 - AUC: 0.5805\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6755 - AUC: 0.5801\n",
      "Epoch 168/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6754 - AUC: 0.5799\n",
      "Epoch 169/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6756 - AUC: 0.5801\n",
      "Epoch 170/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6754 - AUC: 0.5801\n",
      "Epoch 171/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6757 - AUC: 0.5797\n",
      "Epoch 172/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6755 - AUC: 0.5799\n",
      "Epoch 173/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6757 - AUC: 0.5802\n",
      "Epoch 174/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6753 - AUC: 0.5803\n",
      "Epoch 175/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6751 - AUC: 0.5809\n",
      "Epoch 176/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6752 - AUC: 0.5801\n",
      "Epoch 177/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6753 - AUC: 0.5806\n",
      "Epoch 178/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6751 - AUC: 0.5812\n",
      "Epoch 179/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6751 - AUC: 0.5809\n",
      "Epoch 180/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6756 - AUC: 0.5798\n",
      "Epoch 181/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6755 - AUC: 0.5802\n",
      "Epoch 182/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6752 - AUC: 0.5808\n",
      "Epoch 183/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6750 - AUC: 0.5813\n",
      "Epoch 184/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6748 - AUC: 0.5822\n",
      "Epoch 185/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6750 - AUC: 0.5814\n",
      "Epoch 186/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6748 - AUC: 0.5820\n",
      "Epoch 187/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6750 - AUC: 0.5813\n",
      "Epoch 188/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6749 - AUC: 0.5817\n",
      "Epoch 189/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6746 - AUC: 0.5816\n",
      "Epoch 190/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6751 - AUC: 0.5819\n",
      "Epoch 191/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6744 - AUC: 0.5824\n",
      "Epoch 192/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6746 - AUC: 0.5824\n",
      "Epoch 193/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6748 - AUC: 0.5819\n",
      "Epoch 194/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6748 - AUC: 0.5818\n",
      "Epoch 195/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6745 - AUC: 0.5833\n",
      "Epoch 196/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6744 - AUC: 0.5831\n",
      "Epoch 197/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6747 - AUC: 0.5826\n",
      "Epoch 198/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6746 - AUC: 0.5825\n",
      "Epoch 199/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6744 - AUC: 0.5819\n",
      "Epoch 200/200\n",
      "158/158 [==============================] - 2s 14ms/step - loss: 0.6746 - AUC: 0.5827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f82a0293c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = create_mlp2(\n",
    "    len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf2.fit(X_train, y_train, epochs=200, batch_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def utility_score(df):\n",
    "    \"\"\"Calculate utility score of a dataframe according to formulas defined at\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    df['p'] = df['weight']  * df['resp'] * df['action']\n",
    "    p_i = df.set_index('date')['p'].groupby('date').sum()\n",
    "    t = (p_i.sum() / sqrt((p_i**2).sum())) * (sqrt(250 / p_i.index.size))\n",
    "    return min(max(t, 0), 6) * p_i.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import janestreet\n",
    "\n",
    "env = janestreet.make_env()\n",
    "env_iter = env.iter_test()\n",
    "\n",
    "for test_df, pred_df in env_iter:\n",
    "    if test_df[\"weight\"].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        pred = clf(x_tt, training=False).numpy().item()\n",
    "        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test = dt.fread('~/jane-street-market-prediction/example_test.csv').to_pandas()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tt = test.loc[:, features].values\n",
    "if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15219, 130)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = clf(x_tt, training=False).numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(15219, 1), dtype=float32, numpy=\n",
       "array([[0.5038372 ],\n",
       "       [0.5121065 ],\n",
       "       [0.5251299 ],\n",
       "       ...,\n",
       "       [0.52471834],\n",
       "       [0.4686279 ],\n",
       "       [0.5610788 ]], dtype=float32)>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = train[['date', 'resp','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "2          False\n",
       "3           True\n",
       "6          False\n",
       "7           True\n",
       "           ...  \n",
       "1862550    False\n",
       "1862552    False\n",
       "1862584    False\n",
       "1862587    False\n",
       "1862595    False\n",
       "Name: resp, Length: 1571415, dtype: bool"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['resp'] >= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-7ab6d9e05eb9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= 0)\n"
     ]
    }
   ],
   "source": [
    "pred_df['action'] =  (pred_df['resp']  >= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>resp</th>\n",
       "      <th>weight</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.021435</td>\n",
       "      <td>0.859516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.590949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>1.507813</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>5.554003</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date      resp    weight  action\n",
       "0  86.0 -0.021435  0.859516   False\n",
       "2  86.0 -0.004743  0.590949   False\n",
       "3  86.0  0.001527  0.172997    True\n",
       "6  86.0 -0.001663  1.507813   False\n",
       "7  86.0  0.017121  5.554003    True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "173797.76047460196"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_score(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n",
      "<ipython-input-100-5bbefd95825d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action']  = 0\n",
      "<ipython-input-100-5bbefd95825d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
      "<ipython-input-62-dc2694230efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['p'] = df['weight']  * df['resp'] * df['action']\n"
     ]
    }
   ],
   "source": [
    "uscore = []\n",
    "resp_acf = []\n",
    "for thres in np.linspace(rmean-rstd,rmean+rstd,10,endpoint=False):\n",
    "    pred_df['action']  = 0\n",
    "    pred_df['action'] =  (pred_df['resp']  >= thres)* 1\n",
    "    uscore.append(utility_score(pred_df))\n",
    "    #resp_acf.append([train['action'].autocorr(i) for i in range(1,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmean = pred_df['resp'].mean()\n",
    "rstd= pred_df['resp'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384],\n",
       " [0.012150257495777384]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68318.84445385226,\n",
       " 82544.73523142033,\n",
       " 100259.34653025144,\n",
       " 123464.76964333115,\n",
       " 153514.88353703098,\n",
       " 173685.78466871197,\n",
       " 150100.40646264493,\n",
       " 121269.36689563774,\n",
       " 99446.32712217222,\n",
       " 82328.8786689619]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02673104, -0.02132151, -0.01591198, -0.01050246, -0.00509293,\n",
       "        0.00031659,  0.00572612,  0.01113564,  0.01654517,  0.0219547 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(rmean-rstd,rmean+rstd,10,endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156310"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_df['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(pred_df, index='date', values='action',\n",
    "           aggfunc={'action':[np.sum, np.mean]},fill_value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_tf] *",
   "language": "python",
   "name": "conda-env-kaggle_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
